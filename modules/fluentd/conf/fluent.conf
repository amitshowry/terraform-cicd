# -------------------------------------------------------
# Accept logs from Docker Fluentd logging driver
# Containers configured with log_driver = "fluentd"
# push their stdout/stderr here automatically
# -------------------------------------------------------
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# -------------------------------------------------------
# Rename "source" field to "log_source" to avoid
# conflict with Elasticsearch ECS object mapping
# -------------------------------------------------------
<filter docker.**>
  @type record_transformer
  enable_ruby true
  renew_record false
  <record>
    hostname "#{Socket.gethostname}"
    log_source ${record.dig("source") || "unknown"}
  </record>
  remove_keys source
</filter>

# -------------------------------------------------------
# Send to Logstash via HTTP (built-in output plugin)
# -------------------------------------------------------
<match docker.**>
  @type http
  endpoint http://logstash:8085
  content_type application/json
  json_array true
  <format>
    @type json
  </format>
  <buffer>
    @type file
    path /var/log/fluentd-buffers/http.buffer
    flush_interval 5s
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    flush_at_shutdown true
  </buffer>
  <secondary>
    @type file
    path /var/log/fluentd-failed/http
    compress gzip
  </secondary>
</match>

# -------------------------------------------------------
# Catch-all: log anything not matched to stdout
# -------------------------------------------------------
<match **>
  @type stdout
</match>
